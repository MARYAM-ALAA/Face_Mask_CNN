{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a07e373f-a78b-426c-966c-040aecaf6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from pytube import YouTube\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af346663-b177-485c-bb0e-f4f1ab9aa32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video already exists: D:\\OneDrive\\سطح المكتب\\iti_task\\maryam\\video.mp4\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://youtu.be/eibhK1fgG48?si=LvTwX4fMxfvC9xuG\"\n",
    "save_path = r\"D:\\OneDrive\\سطح المكتب\\iti_task\\maryam\"\n",
    "video_file = os.path.join(save_path, \"video.mp4\")\n",
    "\n",
    "if not os.path.exists(video_file):\n",
    "    print(\"Downloading video...\")\n",
    "    yt = YouTube(video_url)\n",
    "    stream = yt.streams.filter(file_extension=\"mp4\", progressive=True).first()\n",
    "    stream.download(output_path=save_path, filename=\"video.mp4\")\n",
    "    print(\"Video downloaded:\", video_file)\n",
    "else:\n",
    "    print(\"Video already exists:\", video_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17926d64-71a0-42e3-9b60-5efeda1c2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running YOLO...\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 4 handbags, 56.5ms\n",
      "Speed: 1.4ms preprocess, 56.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 handbags, 1 suitcase, 60.1ms\n",
      "Speed: 2.1ms preprocess, 60.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 backpack, 1 handbag, 1 suitcase, 53.3ms\n",
      "Speed: 1.0ms preprocess, 53.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 51.4ms\n",
      "Speed: 1.1ms preprocess, 51.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 1 suitcase, 50.8ms\n",
      "Speed: 1.1ms preprocess, 50.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 handbag, 1 suitcase, 55.2ms\n",
      "Speed: 1.8ms preprocess, 55.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 handbag, 1 suitcase, 50.6ms\n",
      "Speed: 1.0ms preprocess, 50.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 handbag, 57.1ms\n",
      "Speed: 1.3ms preprocess, 57.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 51.8ms\n",
      "Speed: 1.1ms preprocess, 51.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 58.6ms\n",
      "Speed: 1.4ms preprocess, 58.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 56.1ms\n",
      "Speed: 1.3ms preprocess, 56.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 56.8ms\n",
      "Speed: 1.1ms preprocess, 56.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 53.5ms\n",
      "Speed: 1.0ms preprocess, 53.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 51.5ms\n",
      "Speed: 1.0ms preprocess, 51.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 49.5ms\n",
      "Speed: 1.1ms preprocess, 49.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 handbag, 59.6ms\n",
      "Speed: 51.6ms preprocess, 59.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 65.9ms\n",
      "Speed: 1.7ms preprocess, 65.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 handbags, 63.4ms\n",
      "Speed: 1.5ms preprocess, 63.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 handbag, 69.5ms\n",
      "Speed: 1.2ms preprocess, 69.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 62.9ms\n",
      "Speed: 1.8ms preprocess, 62.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 handbag, 54.4ms\n",
      "Speed: 1.0ms preprocess, 54.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 52.1ms\n",
      "Speed: 1.0ms preprocess, 52.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 5 handbags, 56.1ms\n",
      "Speed: 1.0ms preprocess, 56.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 2 handbags, 78.3ms\n",
      "Speed: 2.2ms preprocess, 78.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 backpack, 55.9ms\n",
      "Speed: 1.7ms preprocess, 55.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 backpack, 1 handbag, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 backpack, 1 handbag, 50.6ms\n",
      "Speed: 1.1ms preprocess, 50.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 backpack, 1 handbag, 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 2 handbags, 55.3ms\n",
      "Speed: 1.1ms preprocess, 55.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 handbag, 55.2ms\n",
      "Speed: 1.6ms preprocess, 55.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 backpack, 2 handbags, 54.8ms\n",
      "Speed: 1.2ms preprocess, 54.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 backpack, 2 handbags, 50.8ms\n",
      "Speed: 1.0ms preprocess, 50.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 2 handbags, 57.7ms\n",
      "Speed: 1.5ms preprocess, 57.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 handbags, 50.2ms\n",
      "Speed: 1.0ms preprocess, 50.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 handbags, 55.4ms\n",
      "Speed: 1.3ms preprocess, 55.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 3 handbags, 64.5ms\n",
      "Speed: 1.3ms preprocess, 64.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 handbags, 50.6ms\n",
      "Speed: 1.0ms preprocess, 50.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 handbags, 51.7ms\n",
      "Speed: 1.1ms preprocess, 51.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 handbag, 54.1ms\n",
      "Speed: 1.1ms preprocess, 54.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 1 car, 5 handbags, 50.8ms\n",
      "Speed: 1.0ms preprocess, 50.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 handbag, 50.5ms\n",
      "Speed: 1.3ms preprocess, 50.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 52.6ms\n",
      "Speed: 1.1ms preprocess, 52.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 handbag, 84.0ms\n",
      "Speed: 1.1ms preprocess, 84.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 58.6ms\n",
      "Speed: 1.6ms preprocess, 58.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 handbags, 57.3ms\n",
      "Speed: 1.8ms preprocess, 57.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 handbags, 59.2ms\n",
      "Speed: 1.2ms preprocess, 59.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 handbag, 62.6ms\n",
      "Speed: 1.4ms preprocess, 62.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 handbag, 59.5ms\n",
      "Speed: 1.5ms preprocess, 59.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 handbag, 59.8ms\n",
      "Speed: 1.6ms preprocess, 59.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 handbags, 56.6ms\n",
      "Speed: 1.3ms preprocess, 56.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 42 persons, 10 handbags, 1 suitcase, 57.2ms\n",
      "Speed: 1.2ms preprocess, 57.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 1 suitcase, 54.0ms\n",
      "Speed: 1.3ms preprocess, 54.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 handbag, 46.5ms\n",
      "Speed: 1.1ms preprocess, 46.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 3 handbags, 47.6ms\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 handbag, 67.0ms\n",
      "Speed: 2.4ms preprocess, 67.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 handbag, 56.5ms\n",
      "Speed: 1.5ms preprocess, 56.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 handbag, 54.2ms\n",
      "Speed: 1.9ms preprocess, 54.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 1 handbag, 58.4ms\n",
      "Speed: 1.5ms preprocess, 58.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 handbag, 56.3ms\n",
      "Speed: 1.1ms preprocess, 56.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 54.6ms\n",
      "Speed: 3.6ms preprocess, 54.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 50.6ms\n",
      "Speed: 1.0ms preprocess, 50.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 53.5ms\n",
      "Speed: 3.7ms preprocess, 53.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 49.9ms\n",
      "Speed: 1.2ms preprocess, 49.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 48.4ms\n",
      "Speed: 2.2ms preprocess, 48.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 45.3ms\n",
      "Speed: 1.1ms preprocess, 45.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 56.4ms\n",
      "Speed: 1.5ms preprocess, 56.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 57.5ms\n",
      "Speed: 1.6ms preprocess, 57.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 handbag, 51.0ms\n",
      "Speed: 1.1ms preprocess, 51.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 handbag, 51.6ms\n",
      "Speed: 2.7ms preprocess, 51.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 51.0ms\n",
      "Speed: 1.5ms preprocess, 51.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 handbags, 47.0ms\n",
      "Speed: 1.0ms preprocess, 47.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 handbag, 106.1ms\n",
      "Speed: 1.4ms preprocess, 106.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 handbag, 51.9ms\n",
      "Speed: 1.1ms preprocess, 51.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 handbags, 49.0ms\n",
      "Speed: 1.2ms preprocess, 49.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 handbags, 47.6ms\n",
      "Speed: 1.3ms preprocess, 47.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 handbags, 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 handbags, 55.5ms\n",
      "Speed: 1.6ms preprocess, 55.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 handbag, 53.0ms\n",
      "Speed: 2.3ms preprocess, 53.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 handbag, 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 handbags, 53.9ms\n",
      "Speed: 2.0ms preprocess, 53.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bicycle, 1 backpack, 3 handbags, 55.9ms\n",
      "Speed: 1.7ms preprocess, 55.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 bicycles, 1 backpack, 3 handbags, 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 bicycles, 1 backpack, 3 handbags, 51.5ms\n",
      "Speed: 1.5ms preprocess, 51.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 bicycles, 3 handbags, 56.0ms\n",
      "Speed: 1.8ms preprocess, 56.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 4 handbags, 45.6ms\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 handbags, 56.1ms\n",
      "Speed: 1.8ms preprocess, 56.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 handbags, 52.2ms\n",
      "Speed: 1.1ms preprocess, 52.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bicycle, 5 handbags, 53.1ms\n",
      "Speed: 2.6ms preprocess, 53.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 handbags, 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 handbags, 56.3ms\n",
      "Speed: 1.5ms preprocess, 56.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 handbag, 45.8ms\n",
      "Speed: 1.0ms preprocess, 45.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 handbag, 49.7ms\n",
      "Speed: 1.6ms preprocess, 49.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 motorcycle, 1 handbag, 51.7ms\n",
      "Speed: 1.3ms preprocess, 51.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 motorcycle, 54.3ms\n",
      "Speed: 2.6ms preprocess, 54.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bicycle, 53.6ms\n",
      "Speed: 1.5ms preprocess, 53.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 handbag, 45.9ms\n",
      "Speed: 1.1ms preprocess, 45.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 handbag, 52.3ms\n",
      "Speed: 1.2ms preprocess, 52.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 persons, 45.4ms\n",
      "Speed: 1.0ms preprocess, 45.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 63.2ms\n",
      "Speed: 1.3ms preprocess, 63.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bicycle, 57.5ms\n",
      "Speed: 1.3ms preprocess, 57.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bicycle, 51.2ms\n",
      "Speed: 1.4ms preprocess, 51.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 handbags, 46.4ms\n",
      "Speed: 1.1ms preprocess, 46.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 handbag, 1 chair, 51.2ms\n",
      "Speed: 1.1ms preprocess, 51.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 handbag, 65.2ms\n",
      "Speed: 4.0ms preprocess, 65.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 handbag, 46.5ms\n",
      "Speed: 2.4ms preprocess, 46.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 1 handbag, 50.0ms\n",
      "Speed: 3.7ms preprocess, 50.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 2 backpacks, 1 handbag, 46.9ms\n",
      "Speed: 1.0ms preprocess, 46.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 56.9ms\n",
      "Speed: 1.6ms preprocess, 56.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 52.4ms\n",
      "Speed: 1.2ms preprocess, 52.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 52.3ms\n",
      "Speed: 1.3ms preprocess, 52.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 50.6ms\n",
      "Speed: 1.1ms preprocess, 50.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 57.6ms\n",
      "Speed: 1.5ms preprocess, 57.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 52.3ms\n",
      "Speed: 1.2ms preprocess, 52.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 handbag, 73.4ms\n",
      "Speed: 3.5ms preprocess, 73.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 handbag, 50.8ms\n",
      "Speed: 1.5ms preprocess, 50.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 handbags, 47.5ms\n",
      "Speed: 1.1ms preprocess, 47.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 handbag, 56.8ms\n",
      "Speed: 2.1ms preprocess, 56.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 handbags, 46.1ms\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 handbag, 56.7ms\n",
      "Speed: 1.3ms preprocess, 56.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 handbag, 46.5ms\n",
      "Speed: 1.3ms preprocess, 46.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 1 handbag, 99.6ms\n",
      "Speed: 3.2ms preprocess, 99.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 1 handbag, 58.0ms\n",
      "Speed: 1.4ms preprocess, 58.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 handbag, 45.5ms\n",
      "Speed: 1.1ms preprocess, 45.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 handbag, 56.3ms\n",
      "Speed: 1.5ms preprocess, 56.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 4 cars, 1 handbag, 57.0ms\n",
      "Speed: 1.4ms preprocess, 57.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 cars, 1 handbag, 53.8ms\n",
      "Speed: 2.0ms preprocess, 53.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 cars, 2 handbags, 50.0ms\n",
      "Speed: 1.0ms preprocess, 50.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 1 backpack, 3 handbags, 46.5ms\n",
      "Speed: 1.2ms preprocess, 46.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 1 backpack, 52.9ms\n",
      "Speed: 1.0ms preprocess, 52.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 car, 1 handbag, 45.7ms\n",
      "Speed: 1.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 persons, 1 car, 1 handbag, 53.4ms\n",
      "Speed: 1.8ms preprocess, 53.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 5 handbags, 46.8ms\n",
      "Speed: 1.0ms preprocess, 46.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 handbag, 45.0ms\n",
      "Speed: 1.1ms preprocess, 45.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 57.0ms\n",
      "Speed: 1.2ms preprocess, 57.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 4 cars, 1 handbag, 55.7ms\n",
      "Speed: 1.5ms preprocess, 55.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 car, 1 umbrella, 1 handbag, 45.6ms\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 car, 1 handbag, 51.9ms\n",
      "Speed: 1.2ms preprocess, 51.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 handbag, 54.4ms\n",
      "Speed: 2.7ms preprocess, 54.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 3 handbags, 44.9ms\n",
      "Speed: 1.1ms preprocess, 44.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 handbag, 56.8ms\n",
      "Speed: 1.6ms preprocess, 56.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 handbag, 63.2ms\n",
      "Speed: 1.5ms preprocess, 63.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 1 handbag, 51.2ms\n",
      "Speed: 1.3ms preprocess, 51.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 4 cars, 49.7ms\n",
      "Speed: 1.5ms preprocess, 49.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 cars, 57.8ms\n",
      "Speed: 1.7ms preprocess, 57.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 46.1ms\n",
      "Speed: 1.1ms preprocess, 46.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 car, 57.1ms\n",
      "Speed: 3.2ms preprocess, 57.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bicycle, 47.6ms\n",
      "Speed: 1.1ms preprocess, 47.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bicycle, 1 car, 55.6ms\n",
      "Speed: 1.1ms preprocess, 55.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 46.9ms\n",
      "Speed: 1.1ms preprocess, 46.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 46.1ms\n",
      "Speed: 1.1ms preprocess, 46.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 52.9ms\n",
      "Speed: 1.3ms preprocess, 52.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 skateboard, 46.1ms\n",
      "Speed: 1.1ms preprocess, 46.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 72.8ms\n",
      "Speed: 2.9ms preprocess, 72.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 handbag, 51.6ms\n",
      "Speed: 1.7ms preprocess, 51.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 46.3ms\n",
      "Speed: 1.1ms preprocess, 46.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 58.5ms\n",
      "Speed: 1.2ms preprocess, 58.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 handbag, 108.4ms\n",
      "Speed: 1.1ms preprocess, 108.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 handbag, 56.8ms\n",
      "Speed: 1.3ms preprocess, 56.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 49.3ms\n",
      "Speed: 1.3ms preprocess, 49.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 58.0ms\n",
      "Speed: 1.2ms preprocess, 58.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 46.0ms\n",
      "Speed: 1.1ms preprocess, 46.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 55.2ms\n",
      "Speed: 1.4ms preprocess, 55.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 47.0ms\n",
      "Speed: 1.0ms preprocess, 47.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 69.5ms\n",
      "Speed: 2.2ms preprocess, 69.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 48.9ms\n",
      "Speed: 1.1ms preprocess, 48.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 46.3ms\n",
      "Speed: 1.0ms preprocess, 46.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 60.4ms\n",
      "Speed: 1.1ms preprocess, 60.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 50.7ms\n",
      "Speed: 1.2ms preprocess, 50.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 56.8ms\n",
      "Speed: 1.1ms preprocess, 56.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 cars, 46.0ms\n",
      "Speed: 1.1ms preprocess, 46.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 56.9ms\n",
      "Speed: 1.2ms preprocess, 56.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 57.4ms\n",
      "Speed: 1.1ms preprocess, 57.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 103.6ms\n",
      "Speed: 1.1ms preprocess, 103.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 57.5ms\n",
      "Speed: 1.1ms preprocess, 57.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 4 cars, 1 backpack, 1 handbag, 54.5ms\n",
      "Speed: 1.4ms preprocess, 54.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 1 skateboard, 45.8ms\n",
      "Speed: 1.0ms preprocess, 45.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 55.6ms\n",
      "Speed: 1.0ms preprocess, 55.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 57.8ms\n",
      "Speed: 1.2ms preprocess, 57.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 46.8ms\n",
      "Speed: 1.2ms preprocess, 46.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 56.1ms\n",
      "Speed: 1.3ms preprocess, 56.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 56.6ms\n",
      "Speed: 1.3ms preprocess, 56.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 56.8ms\n",
      "Speed: 1.0ms preprocess, 56.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 3 backpacks, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 51.1ms\n",
      "Speed: 1.0ms preprocess, 51.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 52.8ms\n",
      "Speed: 1.2ms preprocess, 52.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 1 backpack, 46.7ms\n",
      "Speed: 1.1ms preprocess, 46.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 4 backpacks, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 cars, 1 handbag, 107.5ms\n",
      "Speed: 1.2ms preprocess, 107.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 cars, 51.5ms\n",
      "Speed: 1.5ms preprocess, 51.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 46.5ms\n",
      "Speed: 1.1ms preprocess, 46.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 7 cars, 1 backpack, 57.6ms\n",
      "Speed: 1.2ms preprocess, 57.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 2 cars, 55.3ms\n",
      "Speed: 1.7ms preprocess, 55.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 47.5ms\n",
      "Speed: 1.1ms preprocess, 47.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 57.6ms\n",
      "Speed: 1.2ms preprocess, 57.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bicycle, 2 cars, 45.8ms\n",
      "Speed: 1.1ms preprocess, 45.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 2 cars, 57.6ms\n",
      "Speed: 1.2ms preprocess, 57.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 5 cars, 58.9ms\n",
      "Speed: 1.2ms preprocess, 58.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 1 handbag, 46.5ms\n",
      "Speed: 1.2ms preprocess, 46.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 47.5ms\n",
      "Speed: 1.1ms preprocess, 47.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 57.5ms\n",
      "Speed: 1.2ms preprocess, 57.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 130.1ms\n",
      "Speed: 1.1ms preprocess, 130.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 53.8ms\n",
      "Speed: 1.3ms preprocess, 53.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 umbrella, 1 handbag, 1 skateboard, 46.2ms\n",
      "Speed: 1.2ms preprocess, 46.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 57.9ms\n",
      "Speed: 1.1ms preprocess, 57.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 60.2ms\n",
      "Speed: 1.3ms preprocess, 60.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 handbag, 50.2ms\n",
      "Speed: 1.2ms preprocess, 50.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 handbag, 61.7ms\n",
      "Speed: 1.3ms preprocess, 61.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 handbag, 50.7ms\n",
      "Speed: 1.1ms preprocess, 50.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 69.3ms\n",
      "Speed: 1.2ms preprocess, 69.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 handbag, 50.8ms\n",
      "Speed: 1.1ms preprocess, 50.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 56.5ms\n",
      "Speed: 1.1ms preprocess, 56.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 handbags, 1 skateboard, 57.6ms\n",
      "Speed: 1.1ms preprocess, 57.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 66.9ms\n",
      "Speed: 1.1ms preprocess, 66.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 111.1ms\n",
      "Speed: 1.3ms preprocess, 111.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 52.1ms\n",
      "Speed: 1.1ms preprocess, 52.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 56.8ms\n",
      "Speed: 1.1ms preprocess, 56.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 46.0ms\n",
      "Speed: 1.1ms preprocess, 46.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 umbrella, 57.1ms\n",
      "Speed: 1.2ms preprocess, 57.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 backpack, 1 umbrella, 58.5ms\n",
      "Speed: 1.2ms preprocess, 58.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 cars, 1 umbrella, 48.3ms\n",
      "Speed: 1.1ms preprocess, 48.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 umbrella, 55.4ms\n",
      "Speed: 1.4ms preprocess, 55.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 backpack, 1 umbrella, 60.2ms\n",
      "Speed: 1.0ms preprocess, 60.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 backpacks, 49.6ms\n",
      "Speed: 1.1ms preprocess, 49.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 2 backpacks, 47.2ms\n",
      "Speed: 1.1ms preprocess, 47.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 56.2ms\n",
      "Speed: 1.0ms preprocess, 56.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 backpack, 108.4ms\n",
      "Speed: 1.1ms preprocess, 108.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 52.8ms\n",
      "Speed: 1.0ms preprocess, 52.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 backpack, 49.4ms\n",
      "Speed: 1.1ms preprocess, 49.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 57.8ms\n",
      "Speed: 1.1ms preprocess, 57.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 57.2ms\n",
      "Speed: 1.2ms preprocess, 57.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 47.7ms\n",
      "Speed: 1.2ms preprocess, 47.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 car, 56.4ms\n",
      "Speed: 1.1ms preprocess, 56.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 60.4ms\n",
      "Speed: 1.2ms preprocess, 60.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 bottle, 52.7ms\n",
      "Speed: 1.1ms preprocess, 52.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 skateboards, 1 bottle, 55.6ms\n",
      "Speed: 1.1ms preprocess, 55.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 skateboards, 55.8ms\n",
      "Speed: 1.1ms preprocess, 55.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 109.2ms\n",
      "Speed: 1.1ms preprocess, 109.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 1 bottle, 48.4ms\n",
      "Speed: 1.0ms preprocess, 48.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 backpack, 54.4ms\n",
      "Speed: 1.4ms preprocess, 54.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 2 backpacks, 47.4ms\n",
      "Speed: 1.1ms preprocess, 47.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 car, 1 backpack, 47.5ms\n",
      "Speed: 1.1ms preprocess, 47.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 backpack, 54.7ms\n",
      "Speed: 2.9ms preprocess, 54.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 48.4ms\n",
      "Speed: 1.1ms preprocess, 48.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 57.8ms\n",
      "Speed: 1.1ms preprocess, 57.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 48.0ms\n",
      "Speed: 1.1ms preprocess, 48.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 67.5ms\n",
      "Speed: 1.2ms preprocess, 67.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 50.6ms\n",
      "Speed: 1.1ms preprocess, 50.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 108.5ms\n",
      "Speed: 1.3ms preprocess, 108.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 64.3ms\n",
      "Speed: 1.2ms preprocess, 64.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 1 skateboard, 58.3ms\n",
      "Speed: 1.4ms preprocess, 58.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 53.5ms\n",
      "Speed: 1.2ms preprocess, 53.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 cars, 47.4ms\n",
      "Speed: 1.0ms preprocess, 47.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 48.4ms\n",
      "Speed: 1.1ms preprocess, 48.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 62.7ms\n",
      "Speed: 1.4ms preprocess, 62.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 55.6ms\n",
      "Speed: 1.3ms preprocess, 55.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 49.3ms\n",
      "Speed: 2.0ms preprocess, 49.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 54.8ms\n",
      "Speed: 1.1ms preprocess, 54.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 47.6ms\n",
      "Speed: 1.1ms preprocess, 47.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 cars, 124.2ms\n",
      "Speed: 1.1ms preprocess, 124.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 cars, 51.9ms\n",
      "Speed: 1.3ms preprocess, 51.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 45.2ms\n",
      "Speed: 1.1ms preprocess, 45.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bicycle, 57.2ms\n",
      "Speed: 1.4ms preprocess, 57.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bicycle, 1 car, 49.4ms\n",
      "Speed: 1.1ms preprocess, 49.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 57.7ms\n",
      "Speed: 1.1ms preprocess, 57.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 56.9ms\n",
      "Speed: 1.1ms preprocess, 56.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 47.9ms\n",
      "Speed: 1.1ms preprocess, 47.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 59.1ms\n",
      "Speed: 1.4ms preprocess, 59.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 29 persons, 48.3ms\n",
      "Speed: 1.1ms preprocess, 48.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bicycle, 109.6ms\n",
      "Speed: 2.0ms preprocess, 109.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 56.4ms\n",
      "Speed: 1.5ms preprocess, 56.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 56.6ms\n",
      "Speed: 1.3ms preprocess, 56.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 47.8ms\n",
      "Speed: 1.9ms preprocess, 47.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 56.3ms\n",
      "Speed: 1.2ms preprocess, 56.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 56.5ms\n",
      "Speed: 1.2ms preprocess, 56.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 47.4ms\n",
      "Speed: 1.0ms preprocess, 47.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 56.3ms\n",
      "Speed: 1.0ms preprocess, 56.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 backpacks, 56.7ms\n",
      "Speed: 1.0ms preprocess, 56.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 56.4ms\n",
      "Speed: 1.0ms preprocess, 56.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 100.1ms\n",
      "Speed: 1.1ms preprocess, 100.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 56.5ms\n",
      "Speed: 1.0ms preprocess, 56.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 car, 57.9ms\n",
      "Speed: 1.2ms preprocess, 57.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 car, 1 handbag, 47.4ms\n",
      "Speed: 1.1ms preprocess, 47.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 car, 1 handbag, 57.3ms\n",
      "Speed: 1.1ms preprocess, 57.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 skateboard, 46.1ms\n",
      "Speed: 1.1ms preprocess, 46.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 57.8ms\n",
      "Speed: 1.1ms preprocess, 57.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 cars, 1 backpack, 48.7ms\n",
      "Speed: 1.1ms preprocess, 48.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 55.5ms\n",
      "Speed: 1.1ms preprocess, 55.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 49.0ms\n",
      "Speed: 1.3ms preprocess, 49.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 107.8ms\n",
      "Speed: 1.1ms preprocess, 107.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 49.1ms\n",
      "Speed: 1.1ms preprocess, 49.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 cars, 67.7ms\n",
      "Speed: 1.5ms preprocess, 67.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 52.6ms\n",
      "Speed: 1.1ms preprocess, 52.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 handbag, 57.0ms\n",
      "Speed: 1.5ms preprocess, 57.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 backpack, 1 handbag, 57.7ms\n",
      "Speed: 1.1ms preprocess, 57.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 cars, 1 handbag, 56.5ms\n",
      "Speed: 1.8ms preprocess, 56.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 handbag, 50.8ms\n",
      "Speed: 1.2ms preprocess, 50.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 55.8ms\n",
      "Speed: 1.3ms preprocess, 55.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 113.2ms\n",
      "Speed: 1.1ms preprocess, 113.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 1 backpack, 56.5ms\n",
      "Speed: 1.2ms preprocess, 56.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 backpack, 57.9ms\n",
      "Speed: 1.2ms preprocess, 57.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 57.5ms\n",
      "Speed: 1.2ms preprocess, 57.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 66.2ms\n",
      "Speed: 1.7ms preprocess, 66.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 47.1ms\n",
      "Speed: 1.1ms preprocess, 47.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 58.4ms\n",
      "Speed: 1.1ms preprocess, 58.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 cars, 47.0ms\n",
      "Speed: 1.0ms preprocess, 47.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 cars, 75.6ms\n",
      "Speed: 2.2ms preprocess, 75.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 105.0ms\n",
      "Speed: 1.2ms preprocess, 105.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 56.5ms\n",
      "Speed: 1.0ms preprocess, 56.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 58.7ms\n",
      "Speed: 1.1ms preprocess, 58.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 57.3ms\n",
      "Speed: 1.2ms preprocess, 57.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 56.3ms\n",
      "Speed: 1.0ms preprocess, 56.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 handbag, 56.8ms\n",
      "Speed: 0.9ms preprocess, 56.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 handbag, 56.9ms\n",
      "Speed: 1.0ms preprocess, 56.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 56.5ms\n",
      "Speed: 1.0ms preprocess, 56.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 2 cars, 46.7ms\n",
      "Speed: 1.0ms preprocess, 46.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 107.4ms\n",
      "Speed: 1.0ms preprocess, 107.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 2 cars, 2 handbags, 56.1ms\n",
      "Speed: 1.0ms preprocess, 56.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 umbrella, 1 handbag, 59.0ms\n",
      "Speed: 1.2ms preprocess, 59.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 handbag, 45.9ms\n",
      "Speed: 1.1ms preprocess, 45.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 handbag, 58.2ms\n",
      "Speed: 1.0ms preprocess, 58.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 57.9ms\n",
      "Speed: 1.0ms preprocess, 57.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 55.3ms\n",
      "Speed: 1.0ms preprocess, 55.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 backpack, 107.2ms\n",
      "Speed: 1.0ms preprocess, 107.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 umbrella, 1 handbag, 49.3ms\n",
      "Speed: 1.1ms preprocess, 49.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 1 umbrella, 2 handbags, 56.6ms\n",
      "Speed: 1.2ms preprocess, 56.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 umbrella, 55.6ms\n",
      "Speed: 1.0ms preprocess, 55.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 umbrella, 56.2ms\n",
      "Speed: 1.0ms preprocess, 56.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 umbrella, 57.0ms\n",
      "Speed: 1.1ms preprocess, 57.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 umbrella, 51.7ms\n",
      "Speed: 1.2ms preprocess, 51.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 1 umbrella, 51.5ms\n",
      "Speed: 1.0ms preprocess, 51.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 1 umbrella, 51.7ms\n",
      "Speed: 1.1ms preprocess, 51.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 umbrella, 114.0ms\n",
      "Speed: 1.0ms preprocess, 114.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 umbrella, 63.4ms\n",
      "Speed: 1.2ms preprocess, 63.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 backpack, 1 umbrella, 55.9ms\n",
      "Speed: 1.3ms preprocess, 55.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 5 cars, 1 backpack, 2 umbrellas, 1 handbag, 58.8ms\n",
      "Speed: 1.2ms preprocess, 58.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 backpack, 1 handbag, 63.3ms\n",
      "Speed: 1.8ms preprocess, 63.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 1 backpack, 1 umbrella, 68.3ms\n",
      "Speed: 1.3ms preprocess, 68.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 6 cars, 2 backpacks, 1 umbrella, 1 handbag, 2 suitcases, 64.7ms\n",
      "Speed: 1.3ms preprocess, 64.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 bicycles, 5 cars, 54.5ms\n",
      "Speed: 1.4ms preprocess, 54.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 5 cars, 2 backpacks, 1 umbrella, 1 suitcase, 127.9ms\n",
      "Speed: 1.0ms preprocess, 127.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 backpack, 1 umbrella, 1 suitcase, 57.8ms\n",
      "Speed: 1.0ms preprocess, 57.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 5 cars, 1 backpack, 3 umbrellas, 1 handbag, 1 suitcase, 60.4ms\n",
      "Speed: 1.1ms preprocess, 60.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 handbag, 1 suitcase, 63.8ms\n",
      "Speed: 1.0ms preprocess, 63.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 65.6ms\n",
      "Speed: 1.2ms preprocess, 65.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 2 handbags, 1 suitcase, 55.2ms\n",
      "Speed: 1.3ms preprocess, 55.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 2 handbags, 61.3ms\n",
      "Speed: 1.2ms preprocess, 61.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 7 cars, 2 handbags, 71.1ms\n",
      "Speed: 1.2ms preprocess, 71.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 handbag, 118.9ms\n",
      "Speed: 1.6ms preprocess, 118.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 handbag, 55.8ms\n",
      "Speed: 1.1ms preprocess, 55.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 handbag, 57.0ms\n",
      "Speed: 1.0ms preprocess, 57.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 1 handbag, 66.5ms\n",
      "Speed: 1.8ms preprocess, 66.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 57.4ms\n",
      "Speed: 1.1ms preprocess, 57.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 63.2ms\n",
      "Speed: 1.0ms preprocess, 63.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 52.0ms\n",
      "Speed: 1.1ms preprocess, 52.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 53.8ms\n",
      "Speed: 1.1ms preprocess, 53.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 98.8ms\n",
      "Speed: 1.0ms preprocess, 98.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 1 handbag, 57.9ms\n",
      "Speed: 1.2ms preprocess, 57.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 handbag, 57.9ms\n",
      "Speed: 1.0ms preprocess, 57.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 1 handbag, 59.5ms\n",
      "Speed: 1.1ms preprocess, 59.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 handbag, 55.1ms\n",
      "Speed: 1.3ms preprocess, 55.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 56.9ms\n",
      "Speed: 1.2ms preprocess, 56.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 52.2ms\n",
      "Speed: 1.1ms preprocess, 52.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 47.0ms\n",
      "Speed: 1.1ms preprocess, 47.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 1 umbrella, 2 handbags, 108.8ms\n",
      "Speed: 1.0ms preprocess, 108.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 umbrella, 3 handbags, 61.4ms\n",
      "Speed: 1.5ms preprocess, 61.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 umbrella, 2 handbags, 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 1 umbrella, 1 handbag, 69.2ms\n",
      "Speed: 1.1ms preprocess, 69.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 1 umbrella, 2 handbags, 62.1ms\n",
      "Speed: 1.4ms preprocess, 62.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 2 handbags, 60.7ms\n",
      "Speed: 2.1ms preprocess, 60.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 handbag, 65.4ms\n",
      "Speed: 1.4ms preprocess, 65.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 backpack, 1 handbag, 82.2ms\n",
      "Speed: 1.9ms preprocess, 82.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 backpack, 2 handbags, 149.2ms\n",
      "Speed: 1.7ms preprocess, 149.2ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 backpack, 2 umbrellas, 2 handbags, 67.8ms\n",
      "Speed: 2.8ms preprocess, 67.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 handbag, 70.4ms\n",
      "Speed: 1.3ms preprocess, 70.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 backpack, 1 handbag, 64.8ms\n",
      "Speed: 1.7ms preprocess, 64.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 5 cars, 1 handbag, 66.9ms\n",
      "Speed: 2.1ms preprocess, 66.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 15 cars, 1 handbag, 63.2ms\n",
      "Speed: 1.5ms preprocess, 63.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 handbag, 67.6ms\n",
      "Speed: 2.0ms preprocess, 67.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 125.8ms\n",
      "Speed: 1.5ms preprocess, 125.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 1 backpack, 86.4ms\n",
      "Speed: 1.5ms preprocess, 86.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 backpack, 70.2ms\n",
      "Speed: 1.6ms preprocess, 70.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 backpack, 67.9ms\n",
      "Speed: 1.6ms preprocess, 67.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 backpack, 1 handbag, 79.5ms\n",
      "Speed: 1.3ms preprocess, 79.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 backpack, 1 handbag, 79.7ms\n",
      "Speed: 1.9ms preprocess, 79.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 backpack, 1 handbag, 67.8ms\n",
      "Speed: 2.0ms preprocess, 67.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 backpack, 143.3ms\n",
      "Speed: 2.7ms preprocess, 143.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 backpack, 76.5ms\n",
      "Speed: 1.3ms preprocess, 76.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 backpack, 82.0ms\n",
      "Speed: 1.5ms preprocess, 82.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 backpack, 78.9ms\n",
      "Speed: 1.7ms preprocess, 78.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 7 cars, 1 backpack, 81.5ms\n",
      "Speed: 2.2ms preprocess, 81.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 backpack, 75.6ms\n",
      "Speed: 3.0ms preprocess, 75.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 backpack, 69.2ms\n",
      "Speed: 2.4ms preprocess, 69.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 backpack, 1 handbag, 133.7ms\n",
      "Speed: 2.2ms preprocess, 133.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 backpack, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 2 backpacks, 1 handbag, 69.9ms\n",
      "Speed: 1.5ms preprocess, 69.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 backpack, 1 handbag, 75.0ms\n",
      "Speed: 1.9ms preprocess, 75.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 backpack, 1 handbag, 62.3ms\n",
      "Speed: 2.1ms preprocess, 62.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 backpack, 1 handbag, 66.3ms\n",
      "Speed: 1.2ms preprocess, 66.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 1 handbag, 69.2ms\n",
      "Speed: 2.2ms preprocess, 69.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 handbag, 121.8ms\n",
      "Speed: 1.4ms preprocess, 121.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 handbag, 69.6ms\n",
      "Speed: 1.2ms preprocess, 69.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 handbag, 73.3ms\n",
      "Speed: 1.6ms preprocess, 73.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 1 handbag, 69.5ms\n",
      "Speed: 1.7ms preprocess, 69.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 cars, 1 backpack, 1 handbag, 66.3ms\n",
      "Speed: 1.6ms preprocess, 66.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 handbag, 71.1ms\n",
      "Speed: 1.8ms preprocess, 71.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 1 handbag, 71.0ms\n",
      "Speed: 2.1ms preprocess, 71.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 handbag, 119.9ms\n",
      "Speed: 2.2ms preprocess, 119.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 handbag, 71.0ms\n",
      "Speed: 1.5ms preprocess, 71.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 2 handbags, 68.8ms\n",
      "Speed: 1.2ms preprocess, 68.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 backpack, 3 handbags, 72.3ms\n",
      "Speed: 1.7ms preprocess, 72.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 2 backpacks, 2 handbags, 72.4ms\n",
      "Speed: 1.9ms preprocess, 72.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 backpack, 1 handbag, 71.9ms\n",
      "Speed: 1.7ms preprocess, 71.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 2 backpacks, 1 handbag, 76.8ms\n",
      "Speed: 2.1ms preprocess, 76.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 backpack, 1 handbag, 134.7ms\n",
      "Speed: 1.5ms preprocess, 134.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 backpacks, 1 handbag, 79.1ms\n",
      "Speed: 1.5ms preprocess, 79.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 12 cars, 4 backpacks, 1 handbag, 78.4ms\n",
      "Speed: 2.7ms preprocess, 78.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 3 backpacks, 1 handbag, 91.1ms\n",
      "Speed: 1.7ms preprocess, 91.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 2 backpacks, 1 handbag, 75.6ms\n",
      "Speed: 1.9ms preprocess, 75.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 4 cars, 1 handbag, 78.3ms\n",
      "Speed: 1.4ms preprocess, 78.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 4 cars, 1 handbag, 74.1ms\n",
      "Speed: 2.3ms preprocess, 74.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 handbag, 133.7ms\n",
      "Speed: 1.8ms preprocess, 133.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 1 handbag, 74.8ms\n",
      "Speed: 1.6ms preprocess, 74.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 1 handbag, 79.4ms\n",
      "Speed: 1.9ms preprocess, 79.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 1 handbag, 79.3ms\n",
      "Speed: 2.3ms preprocess, 79.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 1 handbag, 86.6ms\n",
      "Speed: 2.6ms preprocess, 86.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 cars, 1 handbag, 83.2ms\n",
      "Speed: 2.3ms preprocess, 83.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 handbag, 72.0ms\n",
      "Speed: 1.5ms preprocess, 72.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 131.2ms\n",
      "Speed: 2.0ms preprocess, 131.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 93.7ms\n",
      "Speed: 2.1ms preprocess, 93.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 6 cars, 1 handbag, 69.4ms\n",
      "Speed: 2.3ms preprocess, 69.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 1 handbag, 75.0ms\n",
      "Speed: 2.2ms preprocess, 75.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 6 cars, 1 handbag, 70.7ms\n",
      "Speed: 2.2ms preprocess, 70.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 70.6ms\n",
      "Speed: 2.1ms preprocess, 70.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 handbag, 57.8ms\n",
      "Speed: 1.4ms preprocess, 57.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 1 handbag, 115.1ms\n",
      "Speed: 1.5ms preprocess, 115.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 73.9ms\n",
      "Speed: 1.6ms preprocess, 73.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 68.1ms\n",
      "Speed: 2.3ms preprocess, 68.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 handbag, 69.4ms\n",
      "Speed: 1.5ms preprocess, 69.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 handbag, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 handbag, 128.0ms\n",
      "Speed: 1.4ms preprocess, 128.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 handbag, 69.0ms\n",
      "Speed: 1.4ms preprocess, 69.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 handbag, 78.9ms\n",
      "Speed: 2.2ms preprocess, 78.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 1 handbag, 69.5ms\n",
      "Speed: 1.6ms preprocess, 69.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 1 handbag, 72.1ms\n",
      "Speed: 1.8ms preprocess, 72.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 backpack, 1 handbag, 60.1ms\n",
      "Speed: 1.4ms preprocess, 60.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 handbag, 127.6ms\n",
      "Speed: 1.3ms preprocess, 127.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 handbags, 72.9ms\n",
      "Speed: 2.3ms preprocess, 72.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 backpack, 71.2ms\n",
      "Speed: 1.5ms preprocess, 71.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 67.3ms\n",
      "Speed: 1.8ms preprocess, 67.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 71.7ms\n",
      "Speed: 2.8ms preprocess, 71.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 handbag, 83.5ms\n",
      "Speed: 2.2ms preprocess, 83.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 139.6ms\n",
      "Speed: 1.5ms preprocess, 139.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 85.8ms\n",
      "Speed: 2.4ms preprocess, 85.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 suitcase, 80.2ms\n",
      "Speed: 1.7ms preprocess, 80.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 94.8ms\n",
      "Speed: 1.7ms preprocess, 94.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 1 backpack, 1 handbag, 69.6ms\n",
      "Speed: 1.9ms preprocess, 69.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 83.6ms\n",
      "Speed: 1.6ms preprocess, 83.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 1 handbag, 147.9ms\n",
      "Speed: 1.9ms preprocess, 147.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 80.8ms\n",
      "Speed: 2.2ms preprocess, 80.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 1 backpack, 74.4ms\n",
      "Speed: 2.6ms preprocess, 74.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 88.5ms\n",
      "Speed: 2.2ms preprocess, 88.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 76.6ms\n",
      "Speed: 1.6ms preprocess, 76.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 63.9ms\n",
      "Speed: 1.8ms preprocess, 63.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 68.5ms\n",
      "Speed: 1.3ms preprocess, 68.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 143.9ms\n",
      "Speed: 1.3ms preprocess, 143.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 65.8ms\n",
      "Speed: 1.4ms preprocess, 65.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 backpack, 73.8ms\n",
      "Speed: 2.2ms preprocess, 73.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 75.7ms\n",
      "Speed: 2.2ms preprocess, 75.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 2 backpacks, 64.8ms\n",
      "Speed: 1.9ms preprocess, 64.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 2 backpacks, 68.4ms\n",
      "Speed: 1.7ms preprocess, 68.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 1 parking meter, 2 backpacks, 121.3ms\n",
      "Speed: 1.8ms preprocess, 121.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 1 backpack, 75.5ms\n",
      "Speed: 1.7ms preprocess, 75.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 backpack, 72.2ms\n",
      "Speed: 1.6ms preprocess, 72.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 1 parking meter, 75.6ms\n",
      "Speed: 1.6ms preprocess, 75.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 parking meter, 69.0ms\n",
      "Speed: 1.4ms preprocess, 69.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 4 parking meters, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 126.9ms\n",
      "Speed: 1.6ms preprocess, 126.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 75.2ms\n",
      "Speed: 2.2ms preprocess, 75.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 2 handbags, 72.0ms\n",
      "Speed: 1.6ms preprocess, 72.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 70.9ms\n",
      "Speed: 1.4ms preprocess, 70.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 68.9ms\n",
      "Speed: 1.3ms preprocess, 68.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 71.7ms\n",
      "Speed: 1.3ms preprocess, 71.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 116.7ms\n",
      "Speed: 1.4ms preprocess, 116.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 74.7ms\n",
      "Speed: 2.3ms preprocess, 74.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 handbag, 70.1ms\n",
      "Speed: 1.6ms preprocess, 70.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 handbag, 79.2ms\n",
      "Speed: 2.1ms preprocess, 79.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 72.8ms\n",
      "Speed: 1.5ms preprocess, 72.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 74.6ms\n",
      "Speed: 2.0ms preprocess, 74.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 handbag, 144.0ms\n",
      "Speed: 1.7ms preprocess, 144.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 handbag, 83.8ms\n",
      "Speed: 1.3ms preprocess, 83.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 handbags, 91.1ms\n",
      "Speed: 2.2ms preprocess, 91.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 74.7ms\n",
      "Speed: 1.7ms preprocess, 74.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 67.9ms\n",
      "Speed: 2.0ms preprocess, 67.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 78.0ms\n",
      "Speed: 1.6ms preprocess, 78.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 144.4ms\n",
      "Speed: 2.4ms preprocess, 144.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 85.5ms\n",
      "Speed: 2.6ms preprocess, 85.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 86.2ms\n",
      "Speed: 2.1ms preprocess, 86.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 handbag, 75.1ms\n",
      "Speed: 2.2ms preprocess, 75.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 77.8ms\n",
      "Speed: 2.3ms preprocess, 77.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 135.1ms\n",
      "Speed: 2.4ms preprocess, 135.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 74.3ms\n",
      "Speed: 1.9ms preprocess, 74.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 handbags, 70.3ms\n",
      "Speed: 2.1ms preprocess, 70.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 handbag, 68.7ms\n",
      "Speed: 1.7ms preprocess, 68.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 67.0ms\n",
      "Speed: 1.7ms preprocess, 67.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 handbag, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 122.5ms\n",
      "Speed: 1.9ms preprocess, 122.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 72.1ms\n",
      "Speed: 1.6ms preprocess, 72.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 handbag, 66.2ms\n",
      "Speed: 1.7ms preprocess, 66.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 2 handbags, 74.0ms\n",
      "Speed: 1.4ms preprocess, 74.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 1 handbag, 76.8ms\n",
      "Speed: 2.1ms preprocess, 76.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 cars, 1 handbag, 70.7ms\n",
      "Speed: 1.4ms preprocess, 70.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 126.2ms\n",
      "Speed: 1.5ms preprocess, 126.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 handbag, 73.8ms\n",
      "Speed: 1.9ms preprocess, 73.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 handbag, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 cars, 1 backpack, 1 handbag, 69.9ms\n",
      "Speed: 2.3ms preprocess, 69.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 handbag, 64.5ms\n",
      "Speed: 1.6ms preprocess, 64.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 cars, 2 handbags, 74.5ms\n",
      "Speed: 1.4ms preprocess, 74.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 cars, 128.9ms\n",
      "Speed: 1.5ms preprocess, 128.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 68.5ms\n",
      "Speed: 1.8ms preprocess, 68.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 handbag, 62.8ms\n",
      "Speed: 2.0ms preprocess, 62.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 5 cars, 2 handbags, 81.1ms\n",
      "Speed: 2.0ms preprocess, 81.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 1 handbag, 78.0ms\n",
      "Speed: 1.6ms preprocess, 78.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 handbag, 85.6ms\n",
      "Speed: 2.3ms preprocess, 85.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 1 handbag, 132.1ms\n",
      "Speed: 1.4ms preprocess, 132.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 3 handbags, 76.3ms\n",
      "Speed: 1.2ms preprocess, 76.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 3 handbags, 73.2ms\n",
      "Speed: 3.1ms preprocess, 73.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 3 handbags, 72.4ms\n",
      "Speed: 1.1ms preprocess, 72.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 handbags, 91.5ms\n",
      "Speed: 1.8ms preprocess, 91.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 handbags, 156.7ms\n",
      "Speed: 2.7ms preprocess, 156.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 1 handbag, 85.4ms\n",
      "Speed: 1.6ms preprocess, 85.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 6 cars, 1 backpack, 1 handbag, 83.8ms\n",
      "Speed: 1.4ms preprocess, 83.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 cars, 2 backpacks, 2 handbags, 79.9ms\n",
      "Speed: 1.9ms preprocess, 79.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 backpack, 3 handbags, 76.8ms\n",
      "Speed: 2.1ms preprocess, 76.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 handbags, 132.2ms\n",
      "Speed: 1.5ms preprocess, 132.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 3 handbags, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 1 handbag, 65.7ms\n",
      "Speed: 1.4ms preprocess, 65.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 handbag, 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 handbags, 72.6ms\n",
      "Speed: 1.6ms preprocess, 72.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 70.3ms\n",
      "Speed: 1.7ms preprocess, 70.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 cars, 1 handbag, 129.8ms\n",
      "Speed: 1.1ms preprocess, 129.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 72.5ms\n",
      "Speed: 1.4ms preprocess, 72.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 7 cars, 5 handbags, 70.9ms\n",
      "Speed: 1.6ms preprocess, 70.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 6 cars, 1 handbag, 81.1ms\n",
      "Speed: 2.4ms preprocess, 81.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 handbag, 84.0ms\n",
      "Speed: 1.1ms preprocess, 84.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 cars, 3 handbags, 160.1ms\n",
      "Speed: 1.6ms preprocess, 160.1ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 cars, 80.6ms\n",
      "Speed: 2.1ms preprocess, 80.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 cars, 80.6ms\n",
      "Speed: 2.1ms preprocess, 80.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 cars, 77.7ms\n",
      "Speed: 2.1ms preprocess, 77.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 cars, 1 handbag, 76.7ms\n",
      "Speed: 2.1ms preprocess, 76.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 backpack, 1 handbag, 133.3ms\n",
      "Speed: 1.0ms preprocess, 133.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 cars, 3 backpacks, 2 handbags, 77.3ms\n",
      "Speed: 1.2ms preprocess, 77.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 persons, 5 cars, 6 backpacks, 3 handbags, 71.6ms\n",
      "Speed: 2.0ms preprocess, 71.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 cars, 4 backpacks, 3 handbags, 81.3ms\n",
      "Speed: 1.9ms preprocess, 81.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 2 handbags, 82.0ms\n",
      "Speed: 2.1ms preprocess, 82.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 2 backpacks, 2 handbags, 129.2ms\n",
      "Speed: 2.1ms preprocess, 129.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 car, 1 handbag, 82.2ms\n",
      "Speed: 1.8ms preprocess, 82.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 1 handbag, 79.2ms\n",
      "Speed: 2.0ms preprocess, 79.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 2 handbags, 90.6ms\n",
      "Speed: 2.8ms preprocess, 90.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 handbags, 80.9ms\n",
      "Speed: 2.1ms preprocess, 80.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 handbag, 160.3ms\n",
      "Speed: 1.3ms preprocess, 160.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 94.1ms\n",
      "Speed: 1.8ms preprocess, 94.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 handbags, 94.0ms\n",
      "Speed: 1.9ms preprocess, 94.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 backpack, 3 handbags, 87.7ms\n",
      "Speed: 1.7ms preprocess, 87.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 backpack, 3 handbags, 96.8ms\n",
      "Speed: 2.6ms preprocess, 96.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 2 backpacks, 4 handbags, 150.6ms\n",
      "Speed: 2.6ms preprocess, 150.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 backpack, 3 handbags, 92.5ms\n",
      "Speed: 1.4ms preprocess, 92.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 10 handbags, 84.7ms\n",
      "Speed: 2.3ms preprocess, 84.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 8 handbags, 81.3ms\n",
      "Speed: 2.2ms preprocess, 81.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 handbags, 75.0ms\n",
      "Speed: 1.4ms preprocess, 75.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 handbag, 163.6ms\n",
      "Speed: 1.7ms preprocess, 163.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 cars, 1 backpack, 1 handbag, 92.1ms\n",
      "Speed: 2.8ms preprocess, 92.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 4 handbags, 96.5ms\n",
      "Speed: 3.4ms preprocess, 96.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 4 cars, 4 handbags, 87.4ms\n",
      "Speed: 3.0ms preprocess, 87.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 4 cars, 5 handbags, 87.0ms\n",
      "Speed: 2.5ms preprocess, 87.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 7 handbags, 144.3ms\n",
      "Speed: 1.9ms preprocess, 144.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 backpacks, 2 handbags, 78.9ms\n",
      "Speed: 1.6ms preprocess, 78.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 backpack, 4 handbags, 81.1ms\n",
      "Speed: 2.3ms preprocess, 81.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 backpack, 4 handbags, 77.3ms\n",
      "Speed: 1.3ms preprocess, 77.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 6 handbags, 77.7ms\n",
      "Speed: 2.0ms preprocess, 77.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 truck, 1 backpack, 4 handbags, 158.3ms\n",
      "Speed: 2.2ms preprocess, 158.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 backpacks, 2 handbags, 75.2ms\n",
      "Speed: 2.9ms preprocess, 75.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 backpacks, 2 handbags, 78.8ms\n",
      "Speed: 1.2ms preprocess, 78.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 backpacks, 2 handbags, 82.2ms\n",
      "Speed: 2.2ms preprocess, 82.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 backpacks, 2 handbags, 68.4ms\n",
      "Speed: 1.5ms preprocess, 68.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 4 backpacks, 3 handbags, 149.8ms\n",
      "Speed: 1.3ms preprocess, 149.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 traffic light, 2 backpacks, 1 handbag, 94.7ms\n",
      "Speed: 1.7ms preprocess, 94.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 backpacks, 3 handbags, 76.3ms\n",
      "Speed: 1.3ms preprocess, 76.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 backpacks, 8 handbags, 75.2ms\n",
      "Speed: 2.1ms preprocess, 75.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 backpacks, 4 handbags, 94.6ms\n",
      "Speed: 2.1ms preprocess, 94.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 truck, 2 backpacks, 6 handbags, 148.6ms\n",
      "Speed: 2.2ms preprocess, 148.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 backpacks, 4 handbags, 88.3ms\n",
      "Speed: 2.0ms preprocess, 88.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 backpack, 5 handbags, 79.5ms\n",
      "Speed: 1.4ms preprocess, 79.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 backpacks, 3 handbags, 86.5ms\n",
      "Speed: 2.2ms preprocess, 86.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Cropped 6561 persons and saved in D:\\OneDrive\\سطح المكتب\\iti_task\\maryam\\tmp\\files\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(save_path, \"tmp\", \"files\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Running YOLO...\")\n",
    "model_yolo = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "frame_count = 0\n",
    "crop_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    results = model_yolo(frame)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls == 0:  # person\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                crop = frame[y1:y2, x1:x2]\n",
    "                crop_path = os.path.join(output_dir, f\"person_{frame_count}_{crop_count}.jpg\")\n",
    "                cv2.imwrite(crop_path, crop)\n",
    "                crop_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"Cropped {crop_count} persons and saved in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21c415c6-d193-4969-82a5-a8d073d651ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6043 images belonging to 2 classes.\n",
      "Found 1510 images belonging to 2 classes.\n",
      "Training CNN...\n",
      "Epoch 1/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 678ms/step - accuracy: 0.8259 - loss: 0.3880 - val_accuracy: 0.9146 - val_loss: 0.2264\n",
      "Epoch 2/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 209ms/step - accuracy: 0.8896 - loss: 0.2630 - val_accuracy: 0.9344 - val_loss: 0.1765\n",
      "Epoch 3/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 212ms/step - accuracy: 0.9088 - loss: 0.2259 - val_accuracy: 0.9490 - val_loss: 0.1545\n",
      "Epoch 4/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 218ms/step - accuracy: 0.9184 - loss: 0.1937 - val_accuracy: 0.9172 - val_loss: 0.2153\n",
      "Epoch 5/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 217ms/step - accuracy: 0.9361 - loss: 0.1634 - val_accuracy: 0.9404 - val_loss: 0.1727\n",
      "Epoch 6/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 215ms/step - accuracy: 0.9497 - loss: 0.1378 - val_accuracy: 0.9543 - val_loss: 0.1495\n",
      "Epoch 7/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 217ms/step - accuracy: 0.9581 - loss: 0.1037 - val_accuracy: 0.9503 - val_loss: 0.1623\n",
      "Epoch 8/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 413ms/step - accuracy: 0.9641 - loss: 0.0966 - val_accuracy: 0.9583 - val_loss: 0.1520\n",
      "Epoch 9/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 211ms/step - accuracy: 0.9696 - loss: 0.0843 - val_accuracy: 0.9464 - val_loss: 0.1698\n",
      "Epoch 10/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 218ms/step - accuracy: 0.9767 - loss: 0.0584 - val_accuracy: 0.9563 - val_loss: 0.1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as mask_classifier.h5\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"D:\\OneDrive\\سطح المكتب\\iti_task\\maryam\\archive\\data\"\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "model_cnn = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(128,128,3)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Training CNN...\")\n",
    "model_cnn.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "\n",
    "# Save model\n",
    "model_cnn.save(\"mask_classifier.h5\")\n",
    "print(\"Model saved as mask_classifier.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abfd64d0-721a-4bb3-bf11-c6d479d4d55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification on cropped images with batching...\n",
      "Processed 32 / 13122 images (0.24%)\n",
      "Processed 64 / 13122 images (0.49%)\n",
      "Processed 96 / 13122 images (0.73%)\n",
      "Processed 128 / 13122 images (0.98%)\n",
      "Processed 160 / 13122 images (1.22%)\n",
      "Processed 192 / 13122 images (1.46%)\n",
      "Processed 224 / 13122 images (1.71%)\n",
      "Processed 256 / 13122 images (1.95%)\n",
      "Processed 288 / 13122 images (2.19%)\n",
      "Processed 320 / 13122 images (2.44%)\n",
      "Processed 352 / 13122 images (2.68%)\n",
      "Processed 384 / 13122 images (2.93%)\n",
      "Processed 416 / 13122 images (3.17%)\n",
      "Processed 448 / 13122 images (3.41%)\n",
      "Processed 480 / 13122 images (3.66%)\n",
      "Processed 512 / 13122 images (3.90%)\n",
      "Processed 544 / 13122 images (4.15%)\n",
      "Processed 576 / 13122 images (4.39%)\n",
      "Processed 608 / 13122 images (4.63%)\n",
      "Processed 640 / 13122 images (4.88%)\n",
      "Processed 672 / 13122 images (5.12%)\n",
      "Processed 704 / 13122 images (5.37%)\n",
      "Processed 736 / 13122 images (5.61%)\n",
      "Processed 768 / 13122 images (5.85%)\n",
      "Processed 800 / 13122 images (6.10%)\n",
      "Processed 832 / 13122 images (6.34%)\n",
      "Processed 864 / 13122 images (6.58%)\n",
      "Processed 896 / 13122 images (6.83%)\n",
      "Processed 928 / 13122 images (7.07%)\n",
      "Processed 960 / 13122 images (7.32%)\n",
      "Processed 992 / 13122 images (7.56%)\n",
      "Processed 1024 / 13122 images (7.80%)\n",
      "Processed 1056 / 13122 images (8.05%)\n",
      "Processed 1088 / 13122 images (8.29%)\n",
      "Processed 1120 / 13122 images (8.54%)\n",
      "Processed 1152 / 13122 images (8.78%)\n",
      "Processed 1184 / 13122 images (9.02%)\n",
      "Processed 1216 / 13122 images (9.27%)\n",
      "Processed 1248 / 13122 images (9.51%)\n",
      "Processed 1280 / 13122 images (9.75%)\n",
      "Processed 1312 / 13122 images (10.00%)\n",
      "Processed 1344 / 13122 images (10.24%)\n",
      "Processed 1376 / 13122 images (10.49%)\n",
      "Processed 1408 / 13122 images (10.73%)\n",
      "Processed 1440 / 13122 images (10.97%)\n",
      "Processed 1472 / 13122 images (11.22%)\n",
      "Processed 1504 / 13122 images (11.46%)\n",
      "Processed 1536 / 13122 images (11.71%)\n",
      "Processed 1568 / 13122 images (11.95%)\n",
      "Processed 1600 / 13122 images (12.19%)\n",
      "Processed 1632 / 13122 images (12.44%)\n",
      "Processed 1664 / 13122 images (12.68%)\n",
      "Processed 1696 / 13122 images (12.92%)\n",
      "Processed 1728 / 13122 images (13.17%)\n",
      "Processed 1760 / 13122 images (13.41%)\n",
      "Processed 1792 / 13122 images (13.66%)\n",
      "Processed 1824 / 13122 images (13.90%)\n",
      "Processed 1856 / 13122 images (14.14%)\n",
      "Processed 1888 / 13122 images (14.39%)\n",
      "Processed 1920 / 13122 images (14.63%)\n",
      "Processed 1952 / 13122 images (14.88%)\n",
      "Processed 1984 / 13122 images (15.12%)\n",
      "Processed 2016 / 13122 images (15.36%)\n",
      "Processed 2048 / 13122 images (15.61%)\n",
      "Processed 2080 / 13122 images (15.85%)\n",
      "Processed 2112 / 13122 images (16.10%)\n",
      "Processed 2144 / 13122 images (16.34%)\n",
      "Processed 2176 / 13122 images (16.58%)\n",
      "Processed 2208 / 13122 images (16.83%)\n",
      "Processed 2240 / 13122 images (17.07%)\n",
      "Processed 2272 / 13122 images (17.31%)\n",
      "Processed 2304 / 13122 images (17.56%)\n",
      "Processed 2336 / 13122 images (17.80%)\n",
      "Processed 2368 / 13122 images (18.05%)\n",
      "Processed 2400 / 13122 images (18.29%)\n",
      "Processed 2432 / 13122 images (18.53%)\n",
      "Processed 2464 / 13122 images (18.78%)\n",
      "Processed 2496 / 13122 images (19.02%)\n",
      "Processed 2528 / 13122 images (19.27%)\n",
      "Processed 2560 / 13122 images (19.51%)\n",
      "Processed 2592 / 13122 images (19.75%)\n",
      "Processed 2624 / 13122 images (20.00%)\n",
      "Processed 2656 / 13122 images (20.24%)\n",
      "Processed 2688 / 13122 images (20.48%)\n",
      "Processed 2720 / 13122 images (20.73%)\n",
      "Processed 2752 / 13122 images (20.97%)\n",
      "Processed 2784 / 13122 images (21.22%)\n",
      "Processed 2816 / 13122 images (21.46%)\n",
      "Processed 2848 / 13122 images (21.70%)\n",
      "Processed 2880 / 13122 images (21.95%)\n",
      "Processed 2912 / 13122 images (22.19%)\n",
      "Processed 2944 / 13122 images (22.44%)\n",
      "Processed 2976 / 13122 images (22.68%)\n",
      "Processed 3008 / 13122 images (22.92%)\n",
      "Processed 3040 / 13122 images (23.17%)\n",
      "Processed 3072 / 13122 images (23.41%)\n",
      "Processed 3104 / 13122 images (23.65%)\n",
      "Processed 3136 / 13122 images (23.90%)\n",
      "Processed 3168 / 13122 images (24.14%)\n",
      "Processed 3200 / 13122 images (24.39%)\n",
      "Processed 3232 / 13122 images (24.63%)\n",
      "Processed 3264 / 13122 images (24.87%)\n",
      "Processed 3296 / 13122 images (25.12%)\n",
      "Processed 3328 / 13122 images (25.36%)\n",
      "Processed 3360 / 13122 images (25.61%)\n",
      "Processed 3392 / 13122 images (25.85%)\n",
      "Processed 3424 / 13122 images (26.09%)\n",
      "Processed 3456 / 13122 images (26.34%)\n",
      "Processed 3488 / 13122 images (26.58%)\n",
      "Processed 3520 / 13122 images (26.83%)\n",
      "Processed 3552 / 13122 images (27.07%)\n",
      "Processed 3584 / 13122 images (27.31%)\n",
      "Processed 3616 / 13122 images (27.56%)\n",
      "Processed 3648 / 13122 images (27.80%)\n",
      "Processed 3680 / 13122 images (28.04%)\n",
      "Processed 3712 / 13122 images (28.29%)\n",
      "Processed 3744 / 13122 images (28.53%)\n",
      "Processed 3776 / 13122 images (28.78%)\n",
      "Processed 3808 / 13122 images (29.02%)\n",
      "Processed 3840 / 13122 images (29.26%)\n",
      "Processed 3872 / 13122 images (29.51%)\n",
      "Processed 3904 / 13122 images (29.75%)\n",
      "Processed 3936 / 13122 images (30.00%)\n",
      "Processed 3968 / 13122 images (30.24%)\n",
      "Processed 4000 / 13122 images (30.48%)\n",
      "Processed 4032 / 13122 images (30.73%)\n",
      "Processed 4064 / 13122 images (30.97%)\n",
      "Processed 4096 / 13122 images (31.21%)\n",
      "Processed 4128 / 13122 images (31.46%)\n",
      "Processed 4160 / 13122 images (31.70%)\n",
      "Processed 4192 / 13122 images (31.95%)\n",
      "Processed 4224 / 13122 images (32.19%)\n",
      "Processed 4256 / 13122 images (32.43%)\n",
      "Processed 4288 / 13122 images (32.68%)\n",
      "Processed 4320 / 13122 images (32.92%)\n",
      "Processed 4352 / 13122 images (33.17%)\n",
      "Processed 4384 / 13122 images (33.41%)\n",
      "Processed 4416 / 13122 images (33.65%)\n",
      "Processed 4448 / 13122 images (33.90%)\n",
      "Processed 4480 / 13122 images (34.14%)\n",
      "Processed 4512 / 13122 images (34.39%)\n",
      "Processed 4544 / 13122 images (34.63%)\n",
      "Processed 4576 / 13122 images (34.87%)\n",
      "Processed 4608 / 13122 images (35.12%)\n",
      "Processed 4640 / 13122 images (35.36%)\n",
      "Processed 4672 / 13122 images (35.60%)\n",
      "Processed 4704 / 13122 images (35.85%)\n",
      "Processed 4736 / 13122 images (36.09%)\n",
      "Processed 4768 / 13122 images (36.34%)\n",
      "Processed 4800 / 13122 images (36.58%)\n",
      "Processed 4832 / 13122 images (36.82%)\n",
      "Processed 4864 / 13122 images (37.07%)\n",
      "Processed 4896 / 13122 images (37.31%)\n",
      "Processed 4928 / 13122 images (37.56%)\n",
      "Processed 4960 / 13122 images (37.80%)\n",
      "Processed 4992 / 13122 images (38.04%)\n",
      "Processed 5024 / 13122 images (38.29%)\n",
      "Processed 5056 / 13122 images (38.53%)\n",
      "Processed 5088 / 13122 images (38.77%)\n",
      "Processed 5120 / 13122 images (39.02%)\n",
      "Processed 5152 / 13122 images (39.26%)\n",
      "Processed 5184 / 13122 images (39.51%)\n",
      "Processed 5216 / 13122 images (39.75%)\n",
      "Processed 5248 / 13122 images (39.99%)\n",
      "Processed 5280 / 13122 images (40.24%)\n",
      "Processed 5312 / 13122 images (40.48%)\n",
      "Processed 5344 / 13122 images (40.73%)\n",
      "Processed 5376 / 13122 images (40.97%)\n",
      "Processed 5408 / 13122 images (41.21%)\n",
      "Processed 5440 / 13122 images (41.46%)\n",
      "Processed 5472 / 13122 images (41.70%)\n",
      "Processed 5504 / 13122 images (41.94%)\n",
      "Processed 5536 / 13122 images (42.19%)\n",
      "Processed 5568 / 13122 images (42.43%)\n",
      "Processed 5600 / 13122 images (42.68%)\n",
      "Processed 5632 / 13122 images (42.92%)\n",
      "Processed 5664 / 13122 images (43.16%)\n",
      "Processed 5696 / 13122 images (43.41%)\n",
      "Processed 5728 / 13122 images (43.65%)\n",
      "Processed 5760 / 13122 images (43.90%)\n",
      "Processed 5792 / 13122 images (44.14%)\n",
      "Processed 5824 / 13122 images (44.38%)\n",
      "Processed 5856 / 13122 images (44.63%)\n",
      "Processed 5888 / 13122 images (44.87%)\n",
      "Processed 5920 / 13122 images (45.12%)\n",
      "Processed 5952 / 13122 images (45.36%)\n",
      "Processed 5984 / 13122 images (45.60%)\n",
      "Processed 6016 / 13122 images (45.85%)\n",
      "Processed 6048 / 13122 images (46.09%)\n",
      "Processed 6080 / 13122 images (46.33%)\n",
      "Processed 6112 / 13122 images (46.58%)\n",
      "Processed 6144 / 13122 images (46.82%)\n",
      "Processed 6176 / 13122 images (47.07%)\n",
      "Processed 6208 / 13122 images (47.31%)\n",
      "Processed 6240 / 13122 images (47.55%)\n",
      "Processed 6272 / 13122 images (47.80%)\n",
      "Processed 6304 / 13122 images (48.04%)\n",
      "Processed 6336 / 13122 images (48.29%)\n",
      "Processed 6368 / 13122 images (48.53%)\n",
      "Processed 6400 / 13122 images (48.77%)\n",
      "Processed 6432 / 13122 images (49.02%)\n",
      "Processed 6464 / 13122 images (49.26%)\n",
      "Processed 6496 / 13122 images (49.50%)\n",
      "Processed 6528 / 13122 images (49.75%)\n",
      "Processed 6560 / 13122 images (49.99%)\n",
      "Processed 6592 / 13122 images (50.24%)\n",
      "Processed 6624 / 13122 images (50.48%)\n",
      "Processed 6656 / 13122 images (50.72%)\n",
      "Processed 6688 / 13122 images (50.97%)\n",
      "Processed 6720 / 13122 images (51.21%)\n",
      "Processed 6752 / 13122 images (51.46%)\n",
      "Processed 6784 / 13122 images (51.70%)\n",
      "Processed 6816 / 13122 images (51.94%)\n",
      "Processed 6848 / 13122 images (52.19%)\n",
      "Processed 6880 / 13122 images (52.43%)\n",
      "Processed 6912 / 13122 images (52.67%)\n",
      "Processed 6944 / 13122 images (52.92%)\n",
      "Processed 6976 / 13122 images (53.16%)\n",
      "Processed 7008 / 13122 images (53.41%)\n",
      "Processed 7040 / 13122 images (53.65%)\n",
      "Processed 7072 / 13122 images (53.89%)\n",
      "Processed 7104 / 13122 images (54.14%)\n",
      "Processed 7136 / 13122 images (54.38%)\n",
      "Processed 7168 / 13122 images (54.63%)\n",
      "Processed 7200 / 13122 images (54.87%)\n",
      "Processed 7232 / 13122 images (55.11%)\n",
      "Processed 7264 / 13122 images (55.36%)\n",
      "Processed 7296 / 13122 images (55.60%)\n",
      "Processed 7328 / 13122 images (55.85%)\n",
      "Processed 7360 / 13122 images (56.09%)\n",
      "Processed 7392 / 13122 images (56.33%)\n",
      "Processed 7424 / 13122 images (56.58%)\n",
      "Processed 7456 / 13122 images (56.82%)\n",
      "Processed 7488 / 13122 images (57.06%)\n",
      "Processed 7520 / 13122 images (57.31%)\n",
      "Processed 7552 / 13122 images (57.55%)\n",
      "Processed 7584 / 13122 images (57.80%)\n",
      "Processed 7616 / 13122 images (58.04%)\n",
      "Processed 7648 / 13122 images (58.28%)\n",
      "Processed 7680 / 13122 images (58.53%)\n",
      "Processed 7712 / 13122 images (58.77%)\n",
      "Processed 7744 / 13122 images (59.02%)\n",
      "Processed 7776 / 13122 images (59.26%)\n",
      "Processed 7808 / 13122 images (59.50%)\n",
      "Processed 7840 / 13122 images (59.75%)\n",
      "Processed 7872 / 13122 images (59.99%)\n",
      "Processed 7904 / 13122 images (60.23%)\n",
      "Processed 7936 / 13122 images (60.48%)\n",
      "Processed 7968 / 13122 images (60.72%)\n",
      "Processed 8000 / 13122 images (60.97%)\n",
      "Processed 8032 / 13122 images (61.21%)\n",
      "Processed 8064 / 13122 images (61.45%)\n",
      "Processed 8096 / 13122 images (61.70%)\n",
      "Processed 8128 / 13122 images (61.94%)\n",
      "Processed 8160 / 13122 images (62.19%)\n",
      "Processed 8192 / 13122 images (62.43%)\n",
      "Processed 8224 / 13122 images (62.67%)\n",
      "Processed 8256 / 13122 images (62.92%)\n",
      "Processed 8288 / 13122 images (63.16%)\n",
      "Processed 8320 / 13122 images (63.40%)\n",
      "Processed 8352 / 13122 images (63.65%)\n",
      "Processed 8384 / 13122 images (63.89%)\n",
      "Processed 8416 / 13122 images (64.14%)\n",
      "Processed 8448 / 13122 images (64.38%)\n",
      "Processed 8480 / 13122 images (64.62%)\n",
      "Processed 8512 / 13122 images (64.87%)\n",
      "Processed 8544 / 13122 images (65.11%)\n",
      "Processed 8576 / 13122 images (65.36%)\n",
      "Processed 8608 / 13122 images (65.60%)\n",
      "Processed 8640 / 13122 images (65.84%)\n",
      "Processed 8672 / 13122 images (66.09%)\n",
      "Processed 8704 / 13122 images (66.33%)\n",
      "Processed 8736 / 13122 images (66.58%)\n",
      "Processed 8768 / 13122 images (66.82%)\n",
      "Processed 8800 / 13122 images (67.06%)\n",
      "Processed 8832 / 13122 images (67.31%)\n",
      "Processed 8864 / 13122 images (67.55%)\n",
      "Processed 8896 / 13122 images (67.79%)\n",
      "Processed 8928 / 13122 images (68.04%)\n",
      "Processed 8960 / 13122 images (68.28%)\n",
      "Processed 8992 / 13122 images (68.53%)\n",
      "Processed 9024 / 13122 images (68.77%)\n",
      "Processed 9056 / 13122 images (69.01%)\n",
      "Processed 9088 / 13122 images (69.26%)\n",
      "Processed 9120 / 13122 images (69.50%)\n",
      "Processed 9152 / 13122 images (69.75%)\n",
      "Processed 9184 / 13122 images (69.99%)\n",
      "Processed 9216 / 13122 images (70.23%)\n",
      "Processed 9248 / 13122 images (70.48%)\n",
      "Processed 9280 / 13122 images (70.72%)\n",
      "Processed 9312 / 13122 images (70.96%)\n",
      "Processed 9344 / 13122 images (71.21%)\n",
      "Processed 9376 / 13122 images (71.45%)\n",
      "Processed 9408 / 13122 images (71.70%)\n",
      "Processed 9440 / 13122 images (71.94%)\n",
      "Processed 9472 / 13122 images (72.18%)\n",
      "Processed 9504 / 13122 images (72.43%)\n",
      "Processed 9536 / 13122 images (72.67%)\n",
      "Processed 9568 / 13122 images (72.92%)\n",
      "Processed 9600 / 13122 images (73.16%)\n",
      "Processed 9632 / 13122 images (73.40%)\n",
      "Processed 9664 / 13122 images (73.65%)\n",
      "Processed 9696 / 13122 images (73.89%)\n",
      "Processed 9728 / 13122 images (74.14%)\n",
      "Processed 9760 / 13122 images (74.38%)\n",
      "Processed 9792 / 13122 images (74.62%)\n",
      "Processed 9824 / 13122 images (74.87%)\n",
      "Processed 9856 / 13122 images (75.11%)\n",
      "Processed 9888 / 13122 images (75.35%)\n",
      "Processed 9920 / 13122 images (75.60%)\n",
      "Processed 9952 / 13122 images (75.84%)\n",
      "Processed 9984 / 13122 images (76.09%)\n",
      "Processed 10016 / 13122 images (76.33%)\n",
      "Processed 10048 / 13122 images (76.57%)\n",
      "Processed 10080 / 13122 images (76.82%)\n",
      "Processed 10112 / 13122 images (77.06%)\n",
      "Processed 10144 / 13122 images (77.31%)\n",
      "Processed 10176 / 13122 images (77.55%)\n",
      "Processed 10208 / 13122 images (77.79%)\n",
      "Processed 10240 / 13122 images (78.04%)\n",
      "Processed 10272 / 13122 images (78.28%)\n",
      "Processed 10304 / 13122 images (78.52%)\n",
      "Processed 10336 / 13122 images (78.77%)\n",
      "Processed 10368 / 13122 images (79.01%)\n",
      "Processed 10400 / 13122 images (79.26%)\n",
      "Processed 10432 / 13122 images (79.50%)\n",
      "Processed 10464 / 13122 images (79.74%)\n",
      "Processed 10496 / 13122 images (79.99%)\n",
      "Processed 10528 / 13122 images (80.23%)\n",
      "Processed 10560 / 13122 images (80.48%)\n",
      "Processed 10592 / 13122 images (80.72%)\n",
      "Processed 10624 / 13122 images (80.96%)\n",
      "Processed 10656 / 13122 images (81.21%)\n",
      "Processed 10688 / 13122 images (81.45%)\n",
      "Processed 10720 / 13122 images (81.69%)\n",
      "Processed 10752 / 13122 images (81.94%)\n",
      "Processed 10784 / 13122 images (82.18%)\n",
      "Processed 10816 / 13122 images (82.43%)\n",
      "Processed 10848 / 13122 images (82.67%)\n",
      "Processed 10880 / 13122 images (82.91%)\n",
      "Processed 10912 / 13122 images (83.16%)\n",
      "Processed 10944 / 13122 images (83.40%)\n",
      "Processed 10976 / 13122 images (83.65%)\n",
      "Processed 11008 / 13122 images (83.89%)\n",
      "Processed 11040 / 13122 images (84.13%)\n",
      "Processed 11072 / 13122 images (84.38%)\n",
      "Processed 11104 / 13122 images (84.62%)\n",
      "Processed 11136 / 13122 images (84.87%)\n",
      "Processed 11168 / 13122 images (85.11%)\n",
      "Processed 11200 / 13122 images (85.35%)\n",
      "Processed 11232 / 13122 images (85.60%)\n",
      "Processed 11264 / 13122 images (85.84%)\n",
      "Processed 11296 / 13122 images (86.08%)\n",
      "Processed 11328 / 13122 images (86.33%)\n",
      "Processed 11360 / 13122 images (86.57%)\n",
      "Processed 11392 / 13122 images (86.82%)\n",
      "Processed 11424 / 13122 images (87.06%)\n",
      "Processed 11456 / 13122 images (87.30%)\n",
      "Processed 11488 / 13122 images (87.55%)\n",
      "Processed 11520 / 13122 images (87.79%)\n",
      "Processed 11552 / 13122 images (88.04%)\n",
      "Processed 11584 / 13122 images (88.28%)\n",
      "Processed 11616 / 13122 images (88.52%)\n",
      "Processed 11648 / 13122 images (88.77%)\n",
      "Processed 11680 / 13122 images (89.01%)\n",
      "Processed 11712 / 13122 images (89.25%)\n",
      "Processed 11744 / 13122 images (89.50%)\n",
      "Processed 11776 / 13122 images (89.74%)\n",
      "Processed 11808 / 13122 images (89.99%)\n",
      "Processed 11840 / 13122 images (90.23%)\n",
      "Processed 11872 / 13122 images (90.47%)\n",
      "Processed 11904 / 13122 images (90.72%)\n",
      "Processed 11936 / 13122 images (90.96%)\n",
      "Processed 11968 / 13122 images (91.21%)\n",
      "Processed 12000 / 13122 images (91.45%)\n",
      "Processed 12032 / 13122 images (91.69%)\n",
      "Processed 12064 / 13122 images (91.94%)\n",
      "Processed 12096 / 13122 images (92.18%)\n",
      "Processed 12128 / 13122 images (92.42%)\n",
      "Processed 12160 / 13122 images (92.67%)\n",
      "Processed 12192 / 13122 images (92.91%)\n",
      "Processed 12224 / 13122 images (93.16%)\n",
      "Processed 12256 / 13122 images (93.40%)\n",
      "Processed 12288 / 13122 images (93.64%)\n",
      "Processed 12320 / 13122 images (93.89%)\n",
      "Processed 12352 / 13122 images (94.13%)\n",
      "Processed 12384 / 13122 images (94.38%)\n",
      "Processed 12416 / 13122 images (94.62%)\n",
      "Processed 12448 / 13122 images (94.86%)\n",
      "Processed 12480 / 13122 images (95.11%)\n",
      "Processed 12512 / 13122 images (95.35%)\n",
      "Processed 12544 / 13122 images (95.60%)\n",
      "Processed 12576 / 13122 images (95.84%)\n",
      "Processed 12608 / 13122 images (96.08%)\n",
      "Processed 12640 / 13122 images (96.33%)\n",
      "Processed 12672 / 13122 images (96.57%)\n",
      "Processed 12704 / 13122 images (96.81%)\n",
      "Processed 12736 / 13122 images (97.06%)\n",
      "Processed 12768 / 13122 images (97.30%)\n",
      "Processed 12800 / 13122 images (97.55%)\n",
      "Processed 12832 / 13122 images (97.79%)\n",
      "Processed 12864 / 13122 images (98.03%)\n",
      "Processed 12896 / 13122 images (98.28%)\n",
      "Processed 12928 / 13122 images (98.52%)\n",
      "Processed 12960 / 13122 images (98.77%)\n",
      "Processed 12992 / 13122 images (99.01%)\n",
      "Processed 13024 / 13122 images (99.25%)\n",
      "Processed 13056 / 13122 images (99.50%)\n",
      "Processed 13088 / 13122 images (99.74%)\n",
      "Processed 13120 / 13122 images (99.98%)\n",
      "Processed 13122 / 13122 images (100.00%)\n",
      "Predictions for 13122 images saved in: D:\\OneDrive\\سطح المكتب\\iti_task\\maryam\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Running classification on cropped images with batching...\")\n",
    "\n",
    "results_csv = os.path.join(save_path, \"predictions.csv\")\n",
    "batch_size = 32\n",
    "img_size = (128, 128)\n",
    "\n",
    "# get all image paths\n",
    "all_images = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".jpg\")]\n",
    "num_images = len(all_images)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# process in batches\n",
    "for i in range(0, num_images, batch_size):\n",
    "    batch_files = all_images[i:i+batch_size]\n",
    "    batch_data = []\n",
    "\n",
    "    for img_path in batch_files:\n",
    "        img = image.load_img(img_path, target_size=img_size)\n",
    "        img_array = image.img_to_array(img) / 255.0\n",
    "        batch_data.append(img_array)\n",
    "\n",
    "    batch_data = np.array(batch_data)\n",
    "\n",
    "    # predict for the batch\n",
    "    batch_preds = model_cnn.predict(batch_data, verbose=0)\n",
    "\n",
    "    for j, pred in enumerate(batch_preds):\n",
    "        label = 1 if pred[0] > 0.5 else 0\n",
    "        predictions.append((os.path.basename(batch_files[j]), label))\n",
    "\n",
    "    # print progress with percentage\n",
    "    done = min(i+batch_size, num_images)\n",
    "    percent = (done / num_images) * 100\n",
    "    print(f\"Processed {done} / {num_images} images ({percent:.2f}%)\")\n",
    "\n",
    "# save results to csv\n",
    "with open(results_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"filename\", \"prediction\"])\n",
    "    writer.writerows(predictions)\n",
    "\n",
    "print(f\"Predictions for {num_images} images saved in: {results_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b65e05-81a4-4fd4-ad7f-1fe12d0c8bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
